"""
åƒåœ¾éƒµä»¶åˆ†é¡å™¨ç¶²é æ‡‰ç”¨
"""
import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
import plotly.express as px
import plotly.graph_objects as go

# è¨­ç½®é é¢é…ç½®
st.set_page_config(
    page_title="åƒåœ¾éƒµä»¶åˆ†é¡å™¨",
    page_icon="âœ‰ï¸",
    layout="wide"
)

# è¼‰å…¥æ¨¡å‹å’Œå‘é‡å™¨
@st.cache_resource
def load_model_and_vectorizer():
    """è¼‰å…¥æ¨¡å‹å’Œå‘é‡å™¨."""
    base_dir = Path(__file__).parent
    model_path = base_dir / 'models' / 'spam_classifier.joblib'
    
    # è¼‰å…¥æ¨¡å‹
    model = joblib.load(model_path)
    
    # é‡æ–°è¨“ç·´å‘é‡å™¨
    raw_dir = base_dir / 'datasets' / 'raw'
    df = pd.read_csv(raw_dir / 'sms_spam_no_header.csv')
    df.columns = ['label', 'message']
    
    vectorizer = TfidfVectorizer(
        max_features=1000,
        stop_words='english',
        lowercase=True,
        min_df=5
    )
    vectorizer.fit(df['message'])
    
    return model, vectorizer, df

def predict_message(model, vectorizer, message):
    """é æ¸¬å–®æ¢è¨Šæ¯æ˜¯å¦ç‚ºåƒåœ¾éƒµä»¶."""
    # è½‰æ›æ–‡æœ¬ç‚ºç‰¹å¾µå‘é‡
    X = vectorizer.transform([message])
    
    # é æ¸¬
    prediction = model.predict(X)[0]
    # ç²å–æ±ºç­–å‡½æ•¸å€¼ï¼ˆç½®ä¿¡åº¦ï¼‰
    confidence = abs(model.decision_function(X)[0])
    
    return prediction, confidence

def create_word_importance_plot(vectorizer, model, message):
    """å‰µå»ºå–®å­—é‡è¦æ€§çš„è¦–è¦ºåŒ–."""
    # ç²å–ç‰¹å¾µåç¨±ï¼ˆå–®å­—ï¼‰
    feature_names = vectorizer.get_feature_names_out()
    
    # ç²å–è¨Šæ¯çš„ç‰¹å¾µå‘é‡
    X = vectorizer.transform([message])
    
    # ç²å–æ¯å€‹ç‰¹å¾µçš„æ¬Šé‡
    weights = X.toarray()[0] * model.coef_[0]
    
    # å»ºç«‹DataFrame
    word_importance = pd.DataFrame({
        'å–®å­—': feature_names,
        'é‡è¦æ€§': weights
    })
    
    # åªä¿ç•™æœ‰æ¬Šé‡çš„å–®å­—
    word_importance = word_importance[word_importance['é‡è¦æ€§'] != 0]
    
    # æ’åºä¸¦å–å‰15å€‹æœ€é‡è¦çš„å–®å­—
    word_importance = word_importance.nlargest(15, 'é‡è¦æ€§')
    
    # å‰µå»ºé•·æ¢åœ–
    fig = px.bar(
        word_importance,
        x='é‡è¦æ€§',
        y='å–®å­—',
        orientation='h',
        title='å½±éŸ¿åˆ†é¡çµæœçš„é—œéµå­—',
        labels={'é‡è¦æ€§': 'å½±éŸ¿ç¨‹åº¦', 'å–®å­—': ''},
    )
    
    fig.update_traces(marker_color='lightblue')
    fig.update_layout(height=400)
    
    return fig

def create_confidence_gauge(confidence):
    """å‰µå»ºç½®ä¿¡åº¦å„€è¡¨æ¿."""
    fig = go.Figure(go.Indicator(
        mode = "gauge+number",
        value = confidence,
        domain = {'x': [0, 1], 'y': [0, 1]},
        gauge = {
            'axis': {'range': [0, 5]},
            'bar': {'color': "darkblue"},
            'steps': [
                {'range': [0, 1], 'color': 'lightgray'},
                {'range': [1, 2], 'color': 'gray'},
                {'range': [2, 5], 'color': 'lightblue'}
            ],
        },
        title = {'text': "åˆ†é¡ç½®ä¿¡åº¦"}
    ))
    
    fig.update_layout(height=250)
    return fig

def create_dataset_stats(df):
    """å‰µå»ºè³‡æ–™é›†çµ±è¨ˆè¦–è¦ºåŒ–."""
    # è¨ˆç®—æ¨™ç±¤åˆ†å¸ƒ
    label_counts = df['label'].value_counts()
    
    # å‰µå»ºåœ“é¤…åœ–
    fig = px.pie(
        values=label_counts.values,
        names=['æ­£å¸¸éƒµä»¶', 'åƒåœ¾éƒµä»¶'],
        title='è³‡æ–™é›†åˆ†å¸ƒ',
        color_discrete_sequence=['lightblue', 'gray']
    )
    
    fig.update_layout(height=300)
    return fig

def main():
    # è¼‰å…¥æ¨¡å‹å’Œæ•¸æ“š
    model, vectorizer, df = load_model_and_vectorizer()
    
    # é é¢æ¨™é¡Œ
    st.title("âœ‰ï¸ åƒåœ¾éƒµä»¶åµæ¸¬ç³»çµ±")
    st.write("---")
    
    # å‰µå»ºå…©æ¬„å¸ƒå±€
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # è¼¸å…¥å€åŸŸ
        st.subheader("ğŸ“ è¼¸å…¥è¦æª¢æŸ¥çš„è¨Šæ¯")
        message = st.text_area(
            "åœ¨æ­¤è¼¸å…¥éƒµä»¶å…§å®¹",
            height=200,
            key="message_input"
        )
        
        if st.button("é€²è¡Œåˆ†æ", type="primary"):
            if message:
                # é€²è¡Œé æ¸¬
                prediction, confidence = predict_message(model, vectorizer, message)
                
                # é¡¯ç¤ºçµæœ
                st.write("---")
                st.subheader("ğŸ” åˆ†æçµæœ")
                
                # ä½¿ç”¨é¡è‰²å€å¡Šé¡¯ç¤ºçµæœ
                if prediction == 1:
                    st.error("âš ï¸ é€™å¯èƒ½æ˜¯åƒåœ¾éƒµä»¶")
                else:
                    st.success("âœ… é€™å¯èƒ½æ˜¯æ­£å¸¸éƒµä»¶")
                
                # é¡¯ç¤ºç½®ä¿¡åº¦å„€è¡¨æ¿
                st.plotly_chart(create_confidence_gauge(confidence))
                
                # é¡¯ç¤ºé—œéµå­—åˆ†æ
                st.plotly_chart(create_word_importance_plot(vectorizer, model, message))
            else:
                st.warning("è«‹è¼¸å…¥è¦åˆ†æçš„è¨Šæ¯")
    
    with col2:
        # é¡¯ç¤ºè³‡æ–™é›†çµ±è¨ˆ
        st.subheader("ğŸ“Š è¨“ç·´è³‡æ–™çµ±è¨ˆ")
        st.plotly_chart(create_dataset_stats(df))
        
        # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
        st.subheader("â„¹ï¸ æ¨¡å‹è³‡è¨Š")
        st.info("""
        - ä½¿ç”¨ç·šæ€§æ”¯æŒå‘é‡æ©Ÿ(SVM)åˆ†é¡å™¨
        - æº–ç¢ºç‡ï¼š98%
        - è¨“ç·´è³‡æ–™é‡ï¼š5,573ç­†
        """)
        
        # é¡¯ç¤ºä½¿ç”¨èªªæ˜
        st.subheader("ğŸ“– ä½¿ç”¨èªªæ˜")
        st.write("""
        1. åœ¨å·¦å´è¼¸å…¥æƒ³è¦æª¢æŸ¥çš„éƒµä»¶å…§å®¹
        2. é»æ“Šã€Œé€²è¡Œåˆ†æã€æŒ‰éˆ•
        3. ç³»çµ±æœƒé¡¯ç¤º:
           - åˆ†é¡çµæœ
           - åˆ†é¡ç½®ä¿¡åº¦
           - å½±éŸ¿åˆ†é¡çš„é—œéµå­—
        """)

if __name__ == "__main__":
    main()